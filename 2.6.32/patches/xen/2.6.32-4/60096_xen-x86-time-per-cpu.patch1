From: jbeulich@novell.com
Subject: fold per-CPU accounting data into a structure
Patch-mainline: n/a

... to simplify generated code, especially in timer_interrupt(). This
becomes more important with more such data elements added (i.e. by
patches.xen/xen-x86-xtime-lock).

--- sle11sp1-2010-09-07.orig/arch/x86/kernel/time-xen.c	2010-09-15 16:22:51.000000000 +0200
+++ sle11sp1-2010-09-07/arch/x86/kernel/time-xen.c	2010-09-15 16:24:21.000000000 +0200
@@ -57,12 +57,15 @@ static u32 shadow_tv_version;
 
 /* Keep track of last time we did processing/updating of jiffies and xtime. */
 static u64 processed_system_time;   /* System time (ns) at last processing. */
-static DEFINE_PER_CPU(u64, processed_system_time);
-static DEFINE_PER_CPU(u64, accounted_system_time);
 
-/* How much CPU time was spent blocked and how much was 'stolen'? */
-static DEFINE_PER_CPU(u64, processed_stolen_time);
-static DEFINE_PER_CPU(u64, processed_blocked_time);
+struct local_time_info {
+	u64 processed_system;
+	u64 accounted_system;
+	/* How much CPU time was spent blocked and how much was 'stolen'? */
+	u64 accounted_stolen;
+	u64 accounted_blocked;
+};
+static DEFINE_PER_CPU(struct local_time_info, local_time);
 
 /* Current runstate of each CPU (updated automatically by the hypervisor). */
 DEFINE_PER_CPU(struct vcpu_runstate_info, runstate);
@@ -437,7 +440,8 @@ static inline void print_other_cpus(unsi
 
 	for_each_online_cpu(i)
 		if (i != cpu)
-			printk(" %u: %Lx\n", i, per_cpu(processed_system_time, i));
+			printk(" %u: %Lx\n", i,
+			       per_cpu(local_time.processed_system, i));
 }
 
 /*
@@ -450,6 +454,7 @@ static irqreturn_t timer_interrupt(int i
 	unsigned int duty_num, cpu = smp_processor_id();
 	int schedule_clock_was_set_work = 0;
 	struct shadow_time_info *shadow = &per_cpu(shadow_time, cpu);
+	struct local_time_info *local = &per_cpu(local_time, cpu);
 	bool duty = false;
 	struct vcpu_runstate_info runstate;
 
@@ -478,7 +483,7 @@ static irqreturn_t timer_interrupt(int i
 		delta = delta_cpu =
 			shadow->system_timestamp + get_nsec_offset(shadow);
 		delta     -= processed_system_time;
-		delta_cpu -= per_cpu(processed_system_time, cpu);
+		delta_cpu -= local->processed_system;
 
 		get_runstate_snapshot(&runstate);
 	} while (!time_values_up_to_date());
@@ -492,7 +497,7 @@ static irqreturn_t timer_interrupt(int i
 			       "processed=%Lx/%Lx\n",
 			       cpu, delta, delta_cpu, shadow->system_timestamp,
 			       get_nsec_offset(shadow), blocked,
-			       per_cpu(processed_system_time, cpu));
+			       local->processed_system);
 			print_other_cpus(cpu);
 		}
 	} else if (unlikely(delta_cpu < -(s64)permitted_clock_jitter)) {
@@ -504,7 +509,7 @@ static irqreturn_t timer_interrupt(int i
 			       " shadow=%Lx off=%Lx processed=%Lx/%Lx\n",
 			       cpu, delta_cpu, shadow->system_timestamp,
 			       get_nsec_offset(shadow), blocked,
-			       per_cpu(processed_system_time, cpu));
+			       local->processed_system);
 			print_other_cpus(cpu);
 		}
 	} else if (duty) {
@@ -529,11 +534,10 @@ static irqreturn_t timer_interrupt(int i
 	}
 
 	delta = delta_cpu;
-	delta_cpu += per_cpu(processed_system_time, cpu)
-		   - per_cpu(accounted_system_time, cpu);
+	delta_cpu += local->processed_system - local->accounted_system;
 	if (delta >= NS_PER_TICK) {
 		do_div(delta, NS_PER_TICK);
-		per_cpu(processed_system_time, cpu) += delta * NS_PER_TICK;
+		local->processed_system += delta * NS_PER_TICK;
 	}
 
 	if (schedule_clock_was_set_work && keventd_up())
@@ -545,14 +549,14 @@ static irqreturn_t timer_interrupt(int i
 	 */
 	stolen = runstate.time[RUNSTATE_runnable]
 		 + runstate.time[RUNSTATE_offline]
-		 - per_cpu(processed_stolen_time, cpu);
+		 - local->accounted_stolen;
 	if ((stolen > 0) && (delta_cpu > 0)) {
 		delta_cpu -= stolen;
 		if (unlikely(delta_cpu < 0))
 			stolen += delta_cpu; /* clamp local-time progress */
 		do_div(stolen, NS_PER_TICK);
-		per_cpu(processed_stolen_time, cpu) += stolen * NS_PER_TICK;
-		per_cpu(accounted_system_time, cpu) += stolen * NS_PER_TICK;
+		local->accounted_stolen += stolen * NS_PER_TICK;
+		local->accounted_system += stolen * NS_PER_TICK;
 		account_steal_ticks(stolen);
 	}
 
@@ -561,14 +565,14 @@ static irqreturn_t timer_interrupt(int i
 	 * ensures that the ticks are accounted as idle/wait.
 	 */
 	blocked = runstate.time[RUNSTATE_blocked]
-		  - per_cpu(processed_blocked_time, cpu);
+		  - local->accounted_blocked;
 	if ((blocked > 0) && (delta_cpu > 0)) {
 		delta_cpu -= blocked;
 		if (unlikely(delta_cpu < 0))
 			blocked += delta_cpu; /* clamp local-time progress */
 		do_div(blocked, NS_PER_TICK);
-		per_cpu(processed_blocked_time, cpu) += blocked * NS_PER_TICK;
-		per_cpu(accounted_system_time, cpu)  += blocked * NS_PER_TICK;
+		local->accounted_blocked += blocked * NS_PER_TICK;
+		local->accounted_system  += blocked * NS_PER_TICK;
 		account_idle_ticks(blocked);
 	}
 
@@ -577,7 +581,7 @@ static irqreturn_t timer_interrupt(int i
 		cputime_t ct;
 
 		do_div(delta_cpu, NS_PER_TICK);
-		per_cpu(accounted_system_time, cpu) += delta_cpu * NS_PER_TICK;
+		local->accounted_system += delta_cpu * NS_PER_TICK;
 		ct = jiffies_to_cputime(delta_cpu);
 		if (user_mode_vm(get_irq_regs()))
 			account_user_time(current, ct, cputime_to_scaled(ct));
@@ -616,9 +620,9 @@ static void init_missing_ticks_accountin
 {
 	struct vcpu_runstate_info *runstate = setup_runstate_area(cpu);
 
-	per_cpu(processed_blocked_time, cpu) =
+	per_cpu(local_time.accounted_blocked, cpu) =
 		runstate->time[RUNSTATE_blocked];
-	per_cpu(processed_stolen_time, cpu) =
+	per_cpu(local_time.accounted_stolen, cpu) =
 		runstate->time[RUNSTATE_runnable] +
 		runstate->time[RUNSTATE_offline];
 }
@@ -678,8 +682,8 @@ static void xen_clocksource_resume(void)
 			BUG();
 		}
 		get_time_values_from_xen(cpu);
-		per_cpu(accounted_system_time, cpu) =
-		per_cpu(processed_system_time, cpu) =
+		per_cpu(local_time.accounted_system, cpu) =
+		per_cpu(local_time.processed_system, cpu) =
 			per_cpu(shadow_time, 0).system_timestamp;
 		init_missing_ticks_accounting(cpu);
 	}
@@ -780,8 +784,8 @@ void __init time_init(void)
 	get_time_values_from_xen(0);
 
 	processed_system_time = per_cpu(shadow_time, 0).system_timestamp;
-	per_cpu(processed_system_time, 0) = processed_system_time;
-	per_cpu(accounted_system_time, 0) = processed_system_time;
+	per_cpu(local_time.processed_system, 0) = processed_system_time;
+	per_cpu(local_time.accounted_system, 0) = processed_system_time;
 	init_missing_ticks_accounting(0);
 
 	clocksource_register(&clocksource_xen);
@@ -862,7 +866,7 @@ static void stop_hz_timer(void)
 		rcu_enter_nohz();
 		return;
 	}
-	local = per_cpu(processed_system_time, cpu);
+	local = per_cpu(local_time.processed_system, cpu);
 	if ((s64)(singleshot.timeout_abs_ns - local) <= NS_PER_TICK) {
 		cpumask_clear_cpu(cpu, nohz_cpu_mask);
 		singleshot.timeout_abs_ns = local + NS_PER_TICK;
@@ -933,8 +937,8 @@ int __cpuinit local_setup_timer(unsigned
 	do {
 		seq = read_seqbegin(&xtime_lock);
 		/* Use cpu0 timestamp: cpu's shadow is not initialised yet. */
-		per_cpu(accounted_system_time, cpu) =
-		per_cpu(processed_system_time, cpu) =
+		per_cpu(local_time.accounted_system, cpu) =
+		per_cpu(local_time.processed_system, cpu) =
 			per_cpu(shadow_time, 0).system_timestamp;
 		init_missing_ticks_accounting(cpu);
 	} while (read_seqretry(&xtime_lock, seq));
